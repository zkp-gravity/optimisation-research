{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccbc884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from wisard_my import WiSARD1, generate_h3_values, WiSARD2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b1019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mnist dataset\n",
    "train_dataset, test_dataset = get_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0640844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply max poolling with size 2x2\n",
    "train_dataset = [(np.ravel(pooling(x.reshape(28,28), 2, 'max')), y) for x, y in train_dataset]\n",
    "test_dataset = [(np.ravel(pooling(x.reshape(28,28), 2, 'max')), y) for x, y in test_dataset]\n",
    "S = 28 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ddcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarisation usin thermometer encoding\n",
    "bits_per_input = 2\n",
    "train_inputs, train_labels, val_inputs, val_labels, test_inputs, test_labels = binarize_datasets(train_dataset, test_dataset, bits_per_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding \"bad\" bits (bits which are the same almost for all obserations)\n",
    "all_inputs = np.concatenate([train_inputs, test_inputs, val_inputs])\n",
    "good_pixels = np.arange(S*S*2)[(np.mean(all_inputs,axis=0)<1-10**(-3)) & (np.mean(all_inputs,axis=0)>10**(-3))]\n",
    "bad_pixels = np.arange(S*S*2)[(np.mean(all_inputs,axis=0)>1-10**(-3)) | (np.mean(all_inputs,axis=0)<10**(-3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.mean(all_inputs,axis=0)\n",
    "img[bad_pixels] = 0\n",
    "\n",
    "i = 4\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,4))\n",
    "axs[0].imshow(img[:S*S].reshape(S,S))\n",
    "axs[1].imshow(img[S*S:].reshape(S,S))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(img_bool, img_ind, filter_size):\n",
    "    '''\n",
    "    Function to generate square features of size filter_size x filter_size containing only \"good\" bits\n",
    "    \n",
    "    Parameters:\n",
    "    -img_bool: Boolean array. True values denote good pixels. Bad values denote bad pixels.\n",
    "    -img_ind: An array of pixel indices for which to generate features.\n",
    "    '''\n",
    "    \n",
    "    img_size = int(np.sqrt(len(img_bool)))\n",
    "    f0 = np.arange(filter_size).astype(int)\n",
    "    for i in range(1, filter_size):\n",
    "        f0 = np.append(f0, f0[:filter_size] + (i * img_size))\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for i in range(img_size-filter_size+1):\n",
    "        for j in range(img_size-filter_size+1):\n",
    "            f = f0 + (i*img_size) + j            \n",
    "            if np.all(img_bool[f]):\n",
    "                features.append(img_ind[f])\n",
    "    return features          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining features\n",
    "img_bool = np.ones(S * S * 2).astype(bool)\n",
    "img_bool[good_pixels] = True\n",
    "\n",
    "img_bool_1 = img_bool[:S*S]\n",
    "img_bool_2 = img_bool[S*S:]\n",
    "\n",
    "features1 = generate_features(img_bool_1, np.arange(S*S), 3)\n",
    "features2 = generate_features(img_bool_2, np.arange(S*S,2*S*S), 3)\n",
    "\n",
    "features = np.concatenate([features1, features2])\n",
    "features.shape, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5211114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model parameters\n",
    "unit_inputs, unit_entries, unit_hashes = 9, 512, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating random values for h3 hashing function which will be used for feature selection and in future model\n",
    "random_values = generate_h3_values(unit_inputs, unit_entries, unit_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating acc(f) and ord(f) for each feature for bleaching values from 1 to 20\n",
    "ACC = []\n",
    "N_ACTIVE = []\n",
    "\n",
    "for io in tqdm(features):\n",
    "    acc = []\n",
    "    n_active = []\n",
    "\n",
    "    model = WiSARD1(10, unit_inputs, unit_entries, unit_hashes, random_values, input_order=io)\n",
    "\n",
    "    for xv, l in zip(train_inputs, train_labels):\n",
    "        model.train(xv, l)\n",
    "\n",
    "\n",
    "    for bleach in range(1,21):\n",
    "        model.set_bleaching(bleach)\n",
    "        acc_b = 0\n",
    "        n_active_b = 0\n",
    "        for xv, l in zip(val_inputs, val_labels):\n",
    "            predictions = model.predict(xv)\n",
    "            acc_b += predictions[l]\n",
    "            n_active_b += np.sum(predictions)\n",
    "        \n",
    "        acc_b = acc_b / len(val_inputs)\n",
    "        n_active_b = n_active_b / len(val_inputs)\n",
    "\n",
    "        acc.append(acc_b)\n",
    "        n_active.append(n_active_b)\n",
    "        \n",
    "    ACC.append(acc)\n",
    "    N_ACTIVE.append(n_active)\n",
    "\n",
    "BLEACHES = np.array([np.arange(1,21) for i in range(len(ACC))])\n",
    "ACC = np.array(ACC)\n",
    "N_ACTIVE = np.array(N_ACTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_bleach(acc, n_active, bleaches, alpha, beta):\n",
    "    '''\n",
    "    Function to find the best blaeching values for all αβ-significant features.\n",
    "    If feature is not αβ-significant, then set bleaching value to 0. \n",
    "    '''\n",
    "    aux = n_active <= beta\n",
    "    bleaches = bleaches[aux]\n",
    "    acc = acc[aux]\n",
    "\n",
    "    acc = np.round(acc, 2)\n",
    "    aux = acc >= alpha\n",
    "\n",
    "    bleaches = bleaches[aux]\n",
    "\n",
    "    if len(bleaches) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.min(bleaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f068895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for the best α, β and corresponding bleaching values for features.\n",
    "alphas = [0.92, 0.93, 0.94, 0.95, 0.96, 0.97]\n",
    "betas = [5.5, 6, 6.5, 7, 7.5, 8]\n",
    "\n",
    "accs_cheat = []\n",
    "params =  []\n",
    "\n",
    "accs = []\n",
    "\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    for beta in betas:\n",
    "        params.append([alpha,beta])\n",
    "\n",
    "        best_bleaches = [find_best_bleach(acc, n_active, bleaches, alpha, beta) for acc, n_active, bleaches in  zip(ACC, N_ACTIVE, BLEACHES)]\n",
    "        best_bleaches = np.array(best_bleaches)\n",
    "        good_featres = features[np.array(best_bleaches)>0]\n",
    "\n",
    "        if len(good_featres) == 0:\n",
    "            accs.append(0)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            good_model = WiSARD2(10, unit_inputs, unit_entries, unit_hashes, random_values, good_featres)\n",
    "\n",
    "            for xv, l in zip(train_inputs, train_labels):\n",
    "                good_model.train(xv, l)\n",
    "\n",
    "            good_model.set_bleaching(best_bleaches[best_bleaches>0])\n",
    "\n",
    "\n",
    "            predictions = []\n",
    "            for xv in val_inputs:\n",
    "                predictions.append(good_model.predict(xv))\n",
    "\n",
    "            correct_cheat = 0\n",
    "            correct = 0\n",
    "            for l, p in zip(val_labels, predictions):\n",
    "                if l in p:\n",
    "                    correct_cheat += 1\n",
    "                if l == p[0]:\n",
    "                    correct += 1\n",
    "            \n",
    "            accs.append(correct / len(val_labels))\n",
    "            accs_cheat.append(correct_cheat / len(val_labels))\n",
    "best_acc = accs[np.argmax(accs)]\n",
    "best_params = params[np.argmax(accs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding αβ-significant features and bleach value for each feature\n",
    "best_bleaches = [find_best_bleach(acc, n_active, bleaches, best_params[0], best_params[1]) for acc, n_active, bleaches in  zip(ACC, N_ACTIVE, BLEACHES)]\n",
    "best_bleaches = np.array(best_bleaches)\n",
    "good_featres = features[np.array(best_bleaches)>0]\n",
    "good_featres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5554f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model with αβ-significant features and already found bleaching values for each feature\n",
    "good_model = WiSARD2(10, unit_inputs, unit_entries, unit_hashes, random_values, good_featres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning the model and setting bleach values\n",
    "X = np.vstack([train_inputs, val_inputs])\n",
    "Y = np.concatenate([train_labels, val_labels])\n",
    "for xv, l in zip(X, Y):\n",
    "        good_model.train(xv, l)\n",
    "        \n",
    "good_model.set_bleaching(best_bleaches[best_bleaches>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runing inference\n",
    "predictions = []\n",
    "for xv, l in zip(test_inputs, test_labels):\n",
    "    predictions.append(good_model.predict(xv))\n",
    "correct = 0\n",
    "for l, p in zip(test_labels, predictions):\n",
    "    if l == p[0]:\n",
    "        correct += 1\n",
    "correct / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb5483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
